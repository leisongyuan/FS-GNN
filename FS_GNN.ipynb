{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "5OBSacx6Q03m"
      },
      "outputs": [],
      "source": [
        "# import required modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.sparse as sp\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch import nn, optim, Tensor\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.decomposition import PCA\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.datasets import MovieLens100K, MovieLens1M, LastFM\n",
        "from torch_geometric.nn import GCNConv, GATConv\n",
        "from torch_geometric.utils import add_self_loops\n",
        "import pickle\n",
        "\n",
        "from uils import feature_sim_graph, feature_mask, apply_feature_mask\n",
        "from data_process import process_movielens100k, process_movielens1m\n",
        "from ppr_matrix import topk_ppr_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define contants\n",
        "config = {\n",
        "    'dataset': 'MovieLens100K',\n",
        "    'mode': 'ics',\n",
        "    'ppr_topk': 10,\n",
        "    'knn_topk': 10,\n",
        "    'hidden_dim': 64,\n",
        "    'fea_drop_rate': 0.4,\n",
        "    'fc_loss_lambda': 0.5,\n",
        "    'sc_loss_lambda':0.5,\n",
        "    'alpha_ppr': 0.15,\n",
        "    'epsilon': 1e-4,\n",
        "    'aug_user_emb_flag':0,\n",
        "    'aug_item_emb_flag':0\n",
        "} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mZ6-zPxPklE"
      },
      "source": [
        "# Loading the Dataset\n",
        "\n",
        "We split the edges of the graph using a 80/10/10 train/validation/test split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HeteroData(\n",
            "  movie={ x=[1682, 18] },\n",
            "  user={ x=[943, 24] },\n",
            "  (user, rates, movie)={\n",
            "    edge_index=[2, 80000],\n",
            "    rating=[80000],\n",
            "    time=[80000],\n",
            "    edge_label_index=[2, 20000],\n",
            "    edge_label=[20000],\n",
            "  },\n",
            "  (movie, rated_by, user)={\n",
            "    edge_index=[2, 80000],\n",
            "    rating=[80000],\n",
            "    time=[80000],\n",
            "  }\n",
            ")\n",
            "Data load init finish!\n",
            "tensor([[0.3288, 0.0000, 1.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
            "        [0.7260, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.3151, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
            "        ...,\n",
            "        [0.2740, 0.0000, 1.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
            "        [0.6575, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.3014, 0.0000, 1.0000,  ..., 1.0000, 0.0000, 0.0000]])\n",
            "torch.Size([943, 24])\n",
            "tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 0.,  ..., 1., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "torch.Size([1682, 18])\n",
            "tensor([[   0,    0,    0,  ...,  942,  942,  942],\n",
            "        [ 943,  944,  945,  ..., 2009, 2170, 2272]])\n",
            "torch.Size([2, 62129])\n",
            "tensor([6., 4., 5.,  ..., 3., 4., 4.])\n",
            "torch.Size([62129])\n"
          ]
        }
      ],
      "source": [
        "def load_dataset(dataset):\n",
        "    # 选择数据集\n",
        "    def get_dataset(path, name):\n",
        "        if name == 'MovieLens100K':\n",
        "            return MovieLens100K(path)\n",
        "        \n",
        "        if name == 'MovieLens1M':\n",
        "            return MovieLens1M(path)\n",
        "        \n",
        "        if name == 'Yelp':\n",
        "            return LastFM(path)\n",
        "\n",
        "    path = './data/{}/'.format(dataset)\n",
        "    data = get_dataset(path, dataset)\n",
        "    # print(data)\n",
        "    graph = data[0]\n",
        "\n",
        "    return graph\n",
        "\n",
        "graph = load_dataset(config['dataset'])\n",
        "print(graph)\n",
        "\n",
        "if config['dataset'] == 'MovieLens100K':\n",
        "    user_emb, item_emb, train_edge_index, val_edge_index, test_edge_index, train_ratings, val_ratings, test_ratings, user_fea_dim, item_fea_dim = process_movielens100k(\n",
        "        graph, config['mode'])\n",
        "\n",
        "if config['dataset'] == 'MovieLens1M':\n",
        "    user_emb, item_emb, train_edge_index, val_edge_index, test_edge_index, train_ratings, val_ratings, test_ratings, user_fea_dim, item_fea_dim = process_movielens1m(\n",
        "        graph, config['mode'])\n",
        "\n",
        "\n",
        "num_users = user_emb.shape[0]\n",
        "num_items = item_emb.shape[0]\n",
        "\n",
        "print('Data load init finish!')\n",
        "\n",
        "print(user_emb)\n",
        "print(user_emb.size())\n",
        "print(item_emb)\n",
        "print(item_emb.size())\n",
        "print(train_edge_index)\n",
        "print(train_edge_index.size())\n",
        "print(train_ratings)\n",
        "print(train_ratings.size())\n",
        "\n",
        "# # 绘制热力图\n",
        "# row_indices = np.random.choice(item_emb.shape[0], size=18, replace=False)\n",
        "# col_indices = np.random.choice(item_emb.shape[1], size=18, replace=False) # Max columns is 18\n",
        "# subset_matrix = item_emb[np.ix_(row_indices, col_indices)]\n",
        "# plt.figure(figsize=(18, 18)) # 根据需要调整图像大小\n",
        "# sns.heatmap(subset_matrix, cmap='Blues', cbar=True, square=True)\n",
        "# plt.xlabel('项目特征')\n",
        "# plt.ylabel('项目')\n",
        "# plt.title('矩阵可视化')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.3288, 0.0000, 1.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
            "        [0.7260, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.3151, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
            "        ...,\n",
            "        [0.2740, 0.0000, 1.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
            "        [0.6575, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.3014, 0.0000, 1.0000,  ..., 1.0000, 0.0000, 0.0000]])\n",
            "24\n",
            "torch.Size([943, 24])\n",
            "tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 0.,  ..., 1., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "18\n",
            "torch.Size([1682, 18])\n"
          ]
        }
      ],
      "source": [
        "# 获取LLM增强后的属性emb\n",
        "if (config['aug_user_emb_flag']):\n",
        "    augmented_user_df = pd.read_csv('./LLM_attribute_agumentation/aug_data/{}/augmented_user_embed_matrix.csv'.format(config['dataset']), header=None)\n",
        "    user_emb = torch.tensor(augmented_user_df.values, dtype=torch.float32)\n",
        "    user_fea_dim = user_emb.size(1)\n",
        "\n",
        "if (config['aug_item_emb_flag']):\n",
        "    augmented_item_df = pd.read_csv('./LLM_attribute_agumentation/aug_data/{}/augmented_item_embed_matrix.csv'.format(config['dataset']), header=None)\n",
        "    item_emb = torch.tensor(augmented_item_df.values, dtype=torch.float32)\n",
        "    item_fea_dim = item_emb.size(1)\n",
        "\n",
        "print(user_emb)\n",
        "print(user_fea_dim)\n",
        "print(user_emb.size())\n",
        "print(item_emb)\n",
        "print(item_fea_dim)\n",
        "print(item_emb.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User embeddings tensor of shape: torch.Size([943, 24])\n",
            "Item embeddings tensor of shape: torch.Size([1682, 18])\n"
          ]
        }
      ],
      "source": [
        "def load_multiple_npz_as_tensor(npz_file):\n",
        "    emb_list = []\n",
        "    # 使用 numpy.load 来加载 npz 文件\n",
        "    with np.load(npz_file, allow_pickle=True) as data:\n",
        "        for key in data.keys():\n",
        "            # 将每个键对应的嵌入数据转换为 Tensor\n",
        "            emb_tensor = torch.tensor(data[key])\n",
        "            emb_list.append(emb_tensor)\n",
        "    \n",
        "    # 将所有的嵌入张量沿着第 0 维（即行方向）拼接成一个大的二维张量\n",
        "    # 这里假设每个嵌入的形状相同\n",
        "    return torch.cat(emb_list, dim=0)\n",
        "\n",
        "# 加载并转换为二维张量\n",
        "user_sem_emb = load_multiple_npz_as_tensor('./LLM_semantic_agumentation/generation/emb/user_semantic_embeddings.npz').to(torch.float32)\n",
        "item_sem_emb = load_multiple_npz_as_tensor('./LLM_semantic_agumentation/generation/emb/item_semantic_embeddings.npz').to(torch.float32)\n",
        "\n",
        "def apply_pca_to_embeddings(embedding_tensor, target_dim):\n",
        "    \"\"\"\n",
        "    对输入的嵌入张量应用PCA进行降维。\n",
        "\n",
        "    Parameters:\n",
        "    - embedding_tensor (torch.Tensor): 输入的嵌入张量\n",
        "    - target_dim (int): 降维后的目标维度\n",
        "\n",
        "    Returns:\n",
        "    - torch.Tensor: 降维后的嵌入张量\n",
        "    \"\"\"\n",
        "    # 将 PyTorch 张量转换为 NumPy 数组\n",
        "    embedding_np = embedding_tensor.cpu().numpy()\n",
        "    \n",
        "    # 初始化 PCA，设置目标维度\n",
        "    pca = PCA(n_components=target_dim)\n",
        "    \n",
        "    # 对数据进行 PCA 降维\n",
        "    reduced_embedding_np = pca.fit_transform(embedding_np)\n",
        "    \n",
        "    # 将降维后的 NumPy 数组转换回 PyTorch 张量\n",
        "    reduced_embedding_tensor = torch.tensor(reduced_embedding_np, dtype=torch.float32)\n",
        "    \n",
        "    return reduced_embedding_tensor\n",
        "\n",
        "# 对 user_sem_emb 和 item_sem_emb 进行降维\n",
        "user_sem_emb = apply_pca_to_embeddings(user_sem_emb, user_fea_dim)\n",
        "item_sem_emb = apply_pca_to_embeddings(item_sem_emb, item_fea_dim)\n",
        "\n",
        "# 输出降维后的张量形状\n",
        "print(f\"User embeddings tensor of shape: {user_sem_emb.shape}\")\n",
        "print(f\"Item embeddings tensor of shape: {item_sem_emb.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# from scipy.sparse import coo_matrix\n",
        "\n",
        "# # 提取行和列的索引\n",
        "# rows = train_edge_index[0].numpy()\n",
        "# cols = train_edge_index[1].numpy()\n",
        "# ratings = train_ratings.numpy()\n",
        "\n",
        "# # 构造稀疏矩阵\n",
        "# sparse_matrix = coo_matrix((ratings, (rows, cols)))\n",
        "\n",
        "# # 将稀疏矩阵转换为DataFrame\n",
        "# df = pd.DataFrame({\n",
        "#     'row': sparse_matrix.row,\n",
        "#     'col': sparse_matrix.col,\n",
        "#     'data': sparse_matrix.data\n",
        "# })\n",
        "\n",
        "# # 保存为 .csv 文件\n",
        "# sparse_matrix_file_csv = \"train_matrix.csv\"\n",
        "# df.to_csv(sparse_matrix_file_csv, index=False)\n",
        "\n",
        "# # 从 .csv 文件加载数据\n",
        "# loaded_df = pd.read_csv(sparse_matrix_file_csv)\n",
        "\n",
        "# # 重建稀疏矩阵\n",
        "# loaded_sparse_matrix = coo_matrix((loaded_df['data'], (loaded_df['row'], loaded_df['col'])))\n",
        "\n",
        "# # 检查稀疏矩阵的大小和内容\n",
        "# print(\"Shape of the matrix:\", loaded_sparse_matrix.shape)\n",
        "# print(\"Data array (first 10 elements):\", loaded_sparse_matrix.data[:10])\n",
        "# print(\"Row indices (first 10 elements):\", loaded_sparse_matrix.row[:10])\n",
        "# print(\"Column indices (first 10 elements):\", loaded_sparse_matrix.col[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Structure Completion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.构建属性相似的U-U图、I-I图\n",
        "user_sim_edge_index = feature_sim_graph(user_emb, config['knn_topk'])\n",
        "item_sim_edge_index = feature_sim_graph(item_emb, config['knn_topk'])\n",
        "\n",
        "\n",
        "# 2.构建随机游走的U-I图\n",
        "adj = torch.zeros((num_users + num_items, num_users + num_items), dtype=torch.float)\n",
        "adj[train_edge_index[0], train_edge_index[1]] = 1\n",
        "identity_matrix = torch.eye(num_users + num_items)\n",
        "adj = torch.clamp((adj + identity_matrix), 0, 1) # A+I\n",
        "doc_node_indices = list(range(adj.size(0)))\n",
        "\n",
        "# 得到PPR矩阵\n",
        "ppr_adj = topk_ppr_matrix(sp.csr_matrix(adj.cpu(), dtype=float), config['alpha_ppr'], config['epsilon'],\n",
        "                          doc_node_indices, config['ppr_topk'], keep_nodes=doc_node_indices)\n",
        "# print(ppr_adj)\n",
        "\n",
        "# 过滤出交互矩阵的edges\n",
        "rows, cols = ppr_adj.nonzero()\n",
        "ppr_set = set(zip(rows, cols))\n",
        "filtered_extra_edges = {(row, col) for row, col in ppr_set if 0 <= row <= num_users and num_users + 1 <= col <= num_users + num_items}\n",
        "\n",
        "# 将过滤后的交互追加到train_edge_index\n",
        "if filtered_extra_edges:\n",
        "    extra_edges_tensor = torch.tensor(list(filtered_extra_edges), dtype=torch.long).t()\n",
        "    edge_index = torch.cat([train_edge_index, extra_edges_tensor], dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# defines LightGCN model\n",
        "class LightGCN_User(MessagePassing):\n",
        "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_users, embedding_dim, K=2, add_self_loops=False):\n",
        "        \"\"\"Initializes LightGCN Model\n",
        "\n",
        "        Args:\n",
        "            num_users (int): Number of users\n",
        "            num_items (int): Number of items\n",
        "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
        "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
        "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_users = num_users\n",
        "        self.embedding_dim, self.K = embedding_dim, K\n",
        "        self.add_self_loops = add_self_loops\n",
        "\n",
        "        self.users_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
        "        \n",
        "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
        "        \n",
        "    def forward(self, edge_index, user_fea):\n",
        "        \"\"\"Forward propagation of LightGCN Model.\n",
        "\n",
        "        Args:\n",
        "            edge_index (SparseTensor): adjacency matrix\n",
        "\n",
        "        Returns:\n",
        "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
        "        \"\"\"\n",
        "        # 转换为SparseTensor\n",
        "        sparse_edge_index = SparseTensor(row=edge_index[0], col=edge_index[1], sparse_sizes=(\n",
        "            self.num_users, self.num_users))\n",
        "\n",
        "        # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
        "        edge_index_norm = gcn_norm(\n",
        "            sparse_edge_index, add_self_loops=self.add_self_loops)\n",
        "        \n",
        "        emb_0 = self.users_emb.weight # E^0 [num_users, embedding_dim]\n",
        "        embs = [emb_0]\n",
        "        emb_k = emb_0\n",
        "\n",
        "        # multi-scale diffusion\n",
        "        for i in range(self.K):\n",
        "            emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
        "            embs.append(emb_k)\n",
        "\n",
        "        embs = torch.stack(embs, dim=1)\n",
        "        emb_final = torch.mean(embs, dim=1) # E^K [num_users, embedding_dim]\n",
        "        users_emb_final = emb_final # splits into e_u^K and e_i^K\n",
        "        \n",
        "        return users_emb_final\n",
        "    \n",
        "    def message(self, x_j: Tensor) -> Tensor:\n",
        "        return x_j\n",
        "\n",
        "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
        "        # computes \\tilde{A} @ x\n",
        "        return matmul(adj_t, x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# defines LightGCN model\n",
        "class LightGCN_Item(MessagePassing):\n",
        "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_items, embedding_dim, K=2, add_self_loops=False):\n",
        "        \"\"\"Initializes LightGCN Model\n",
        "\n",
        "        Args:\n",
        "            num_users (int): Number of users\n",
        "            num_items (int): Number of items\n",
        "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
        "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
        "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_items = num_items\n",
        "        self.embedding_dim, self.K = embedding_dim, K\n",
        "        self.add_self_loops = add_self_loops\n",
        "        \n",
        "        self.items_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
        "        \n",
        "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
        "\n",
        "    def forward(self, edge_index, item_fea):\n",
        "        \"\"\"Forward propagation of LightGCN Model.\n",
        "\n",
        "        Args:\n",
        "            edge_index (SparseTensor): adjacency matrix\n",
        "\n",
        "        Returns:\n",
        "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
        "        \"\"\"\n",
        "        # 转换为SparseTensor\n",
        "        sparse_edge_index = SparseTensor(row=edge_index[0], col=edge_index[1], sparse_sizes=(\n",
        "            self.num_items, self.num_items))\n",
        "\n",
        "        # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
        "        edge_index_norm = gcn_norm(\n",
        "            sparse_edge_index, add_self_loops=self.add_self_loops)\n",
        "        \n",
        "        emb_0 = self.items_emb.weight # E^0 [num_items, embedding_dim]\n",
        "        embs = [emb_0]\n",
        "        emb_k = emb_0\n",
        "\n",
        "        # multi-scale diffusion\n",
        "        for i in range(self.K):\n",
        "            emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
        "            embs.append(emb_k)\n",
        "\n",
        "        embs = torch.stack(embs, dim=1)\n",
        "        emb_final = torch.mean(embs, dim=1) # E^K [num_items, embedding_dim]\n",
        "        items_emb_final = emb_final # splits into e_u^K and e_i^K\n",
        "        \n",
        "        return items_emb_final\n",
        "    \n",
        "    def message(self, x_j: Tensor) -> Tensor:\n",
        "        return x_j\n",
        "\n",
        "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
        "        # computes \\tilde{A} @ x\n",
        "        return matmul(adj_t, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "o9GvYg9ehDOX"
      },
      "outputs": [],
      "source": [
        "# defines LightGCN model\n",
        "class LightGCN_Pred(MessagePassing):\n",
        "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_users, num_items, embedding_dim, K=2, add_self_loops=False):\n",
        "        \"\"\"Initializes LightGCN Model\n",
        "\n",
        "        Args:\n",
        "            num_users (int): Number of users\n",
        "            num_items (int): Number of items\n",
        "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
        "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
        "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_users, self.num_items = num_users, num_items\n",
        "        self.embedding_dim, self.K = embedding_dim, K\n",
        "        self.add_self_loops = add_self_loops\n",
        "        \n",
        "        self.mlp = nn.Linear(self.embedding_dim * 2, 1)\n",
        "        nn.init.normal_(self.mlp.weight, std=0.1)\n",
        "\n",
        "    def forward(self, edge_index, user_fea, item_fea):\n",
        "        \"\"\"Forward propagation of LightGCN Model.\n",
        "\n",
        "        Args:\n",
        "            edge_index (SparseTensor): adjacency matrix\n",
        "\n",
        "        Returns:\n",
        "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
        "        \"\"\"\n",
        "        # 转换为SparseTensor\n",
        "        sparse_edge_index = SparseTensor(row=edge_index[0], col=edge_index[1], sparse_sizes=(\n",
        "            num_users + num_items, num_users + num_items))\n",
        "\n",
        "        # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
        "        edge_index_norm = gcn_norm(\n",
        "            sparse_edge_index, add_self_loops=self.add_self_loops)\n",
        "        \n",
        "        emb_0 = torch.cat([user_fea, item_fea]) # E^0 [num_users + num_items, embedding_dim]\n",
        "        embs = [emb_0]\n",
        "        emb_k = emb_0\n",
        "\n",
        "        # multi-scale diffusion\n",
        "        for i in range(self.K):\n",
        "            emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
        "            embs.append(emb_k)\n",
        "\n",
        "        embs = torch.stack(embs, dim=1)\n",
        "        emb_final = torch.mean(embs, dim=1) # E^K [num_users + num_items, embedding_dim]\n",
        "        users_emb_final, items_emb_final = torch.split(\n",
        "            emb_final, [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
        "        \n",
        "        # 节点特征分批\n",
        "        users_emb = users_emb_final[edge_index[0]] # [batch_size, embedding_dim]\n",
        "        items_emb = items_emb_final[edge_index[1] - self.num_users] # [batch_size, embedding_dim]\n",
        "\n",
        "        # 为每对用户-物品连接嵌入\n",
        "        combined_emb = torch.cat((users_emb, items_emb), dim = 1) # [batch_size, embedding_dim * 2]\n",
        "        # 将组合的嵌入过MLP\n",
        "        pred_ratings = self.mlp(combined_emb).squeeze() # [batch_size, 1]\n",
        "        \n",
        "        return pred_ratings\n",
        "    \n",
        "    def message(self, x_j: Tensor) -> Tensor:\n",
        "        return x_j\n",
        "\n",
        "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
        "        # computes \\tilde{A} @ x\n",
        "        return matmul(adj_t, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GAE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GAE, self).__init__()\n",
        "        self.encoder = GATConv(in_channels, out_channels, heads=1)\n",
        "        self.decoder = GCNConv(out_channels, in_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        edge_index, _ = add_self_loops(edge_index)\n",
        "        z = F.relu(self.encoder(x, edge_index))\n",
        "        x_recon = self.decoder(z, edge_index)\n",
        "        return z, x_recon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implementing FS_GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FS_GNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_users, \n",
        "                 num_items, \n",
        "                 user_fea_dim, \n",
        "                 item_fea_dim,\n",
        "                 hidden_dim):\n",
        "        super(FS_GNN, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "\n",
        "        self.transform_users = nn.Linear(user_fea_dim, self.hidden_dim)\n",
        "        self.transform_items = nn.Linear(item_fea_dim, self.hidden_dim)\n",
        "\n",
        "        self.concat_fea = nn.Linear(self.hidden_dim * 2, self.hidden_dim)\n",
        "        self.gate_fc = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
        "            nn.Sigmoid()\n",
        "            )\n",
        "        self.gate_user = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
        "            nn.Sigmoid()\n",
        "            )\n",
        "        self.gate_item = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
        "            nn.Sigmoid()\n",
        "            )\n",
        "        self.mlp = nn.Linear(self.hidden_dim * 2, 1)\n",
        "        self.mse_loss = torch.nn.MSELoss()\n",
        "\n",
        "        nn.init.xavier_normal_(self.transform_users.weight)\n",
        "        nn.init.xavier_normal_(self.transform_items.weight)\n",
        "        nn.init.xavier_normal_(self.concat_fea.weight)\n",
        "        nn.init.xavier_uniform_(self.gate_fc[0].weight)\n",
        "        nn.init.xavier_uniform_(self.gate_user[0].weight)\n",
        "        nn.init.xavier_uniform_(self.gate_item[0].weight)\n",
        "        nn.init.normal_(self.mlp.weight, std=0.1)\n",
        "            \n",
        "        # LightGCN layers\n",
        "        self.gcn_pred = LightGCN_Pred(self.num_users, self.num_items, self.hidden_dim)\n",
        "        self.gcn_user = LightGCN_User(self.num_users, self.hidden_dim)\n",
        "        self.gcn_item = LightGCN_Item(self.num_items, self.hidden_dim)\n",
        "        # GAE layers\n",
        "        self.gae = GAE(in_channels = self.hidden_dim, out_channels = self.hidden_dim)\n",
        "\n",
        "    def forward(self, edge_index, user_sim_edge_index, item_sim_edge_index, user_fea_emb, item_fea_emb, user_sem_emb, item_sem_emb, device):\n",
        "    \n",
        "        # 统一维度\n",
        "        user_fea_emb = self.transform_users(user_fea_emb)\n",
        "        item_fea_emb = self.transform_items(item_fea_emb)\n",
        "        user_sem_emb = self.transform_users(user_sem_emb)\n",
        "        item_sem_emb = self.transform_items(item_sem_emb)\n",
        "\n",
        "        '''Feature Completion'''\n",
        "        x = torch.cat([user_fea_emb, item_fea_emb])\n",
        "        mask = feature_mask(x, config['fea_drop_rate'])\n",
        "        apply_feature_mask(x, mask)\n",
        "        z, x_recon = self.gae(x, edge_index)\n",
        "        _, item_fea_gae = torch.split(z, [self.num_users, self.num_items])\n",
        "        # 计算fc_loss\n",
        "        fc_loss = F.mse_loss(x, x_recon) \n",
        "\n",
        "        # 节点属性补全\n",
        "        g = self.gate_fc(torch.cat([item_fea_emb, item_fea_gae], dim=1))  \n",
        "        item_fea_fc = g * item_fea_emb + (1 - g) * item_fea_gae \n",
        "        \n",
        "        '''Structure Completion'''\n",
        "        user_fea_sim = self.gcn_user(user_sim_edge_index, user_fea_emb)\n",
        "        item_fea_sim = self.gcn_item(item_sim_edge_index, item_fea_fc)\n",
        "        # 计算sc_loss\n",
        "        batch_user_fea_sim = user_fea_sim[edge_index[0]] # [batch_size, embedding_dim]\n",
        "        batch_item_fea_sim = item_fea_sim[edge_index[1] - self.num_users] # [batch_size, embedding_dim]\n",
        "        sc_pred = self.mlp(torch.cat((batch_user_fea_sim, batch_item_fea_sim), dim = 1)).squeeze() # [batch_size, 1]\n",
        "        ratings = torch.ones(batch_user_fea_sim.size(0)).to(device)\n",
        "        sc_loss = self.mse_loss(ratings, sc_pred)\n",
        "\n",
        "        # 融合U-U特征和I-I特征\n",
        "        g_user = self.gate_user(torch.cat((user_fea_sim, user_fea_emb), dim=1))  \n",
        "        final_user_fea_emb = g_user * user_fea_sim + (1 - g_user) * user_fea_emb \n",
        "        g_item = self.gate_item(torch.cat((item_fea_sim, item_fea_emb), dim=1))\n",
        "        final_item_fea_emb = g_item * item_fea_sim + (1 - g_item) * item_fea_emb\n",
        "\n",
        "\n",
        "\n",
        "        pred_ratings = self.gcn_pred(edge_index, final_user_fea_emb, final_item_fea_emb)\n",
        "\n",
        "\n",
        "        return pred_ratings, fc_loss, sc_loss, item_fea_gae\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "yr_qESXASsVw"
      },
      "outputs": [],
      "source": [
        "# wrapper function to evaluate model\n",
        "def evaluation(model, real_ratings, edge_index, user_emb, item_emb, batch_size, device):\n",
        "    label_lst, pred_lst = [], []\n",
        "    total_loss, total_rmse, total_mae = 0,0,0\n",
        "    total_count = 0\n",
        "    mse_loss = torch.nn.MSELoss()\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader( \n",
        "        range(edge_index.size(1)),\n",
        "        shuffle=True,\n",
        "        batch_size = batch_size,\n",
        "    )\n",
        "    for index in data_loader:\n",
        "        # 获取批次数据\n",
        "        batch_edges = edge_index[:, index].to(device)\n",
        "        batch_ratings = real_ratings[index].to(device)\n",
        "        \n",
        "        # get pred_matrix\n",
        "        pred_ratings, fc_loss, sc_loss, item_fea_gae = model.forward(batch_edges, user_sim_edge_index, item_sim_edge_index, user_emb, item_emb, user_sem_emb, item_sem_emb, device)\n",
        "        \n",
        "        pred_ratings = pred_ratings.to(device)\n",
        "\n",
        "        pred_loss = mse_loss(batch_ratings, pred_ratings)\n",
        "        \n",
        "        loss = pred_loss + config['fc_loss_lambda'] * fc_loss + config['sc_loss_lambda'] * sc_loss\n",
        "\n",
        "        batch_ratings = batch_ratings.cpu().data.numpy()\n",
        "        pred_ratings = pred_ratings.cpu().data.numpy()\n",
        "\n",
        "        mae = np.sum(np.abs(pred_ratings - batch_ratings))\n",
        "        rmse = np.sum((pred_ratings - batch_ratings) ** 2)\n",
        "        \n",
        "        total_loss += loss.item() * len(batch_ratings)\n",
        "        total_rmse += rmse\n",
        "        total_mae += mae\n",
        "        total_count += len(batch_ratings)\n",
        "\n",
        "    avg_loss = total_loss / total_count\n",
        "    avg_rmse = np.sqrt(total_rmse / total_count)\n",
        "    avg_mae = total_mae / total_count\n",
        "\n",
        "    return avg_loss, avg_mae, avg_rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYw1cUgPTjws"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define contants\n",
        "ITERATIONS = 300\n",
        "BATCH_SIZE = 2048\n",
        "LR = 0.005\n",
        "ITERS_PER_EVAL = 20\n",
        "ITERS_PER_LR_DECAY = 20\n",
        "WEIGHT_DECAY = 0.0005"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49JDkBtKTfE-",
        "outputId": "1df57d45-a5a6-4d0e-9785-14c1e80ae71a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device cuda:0.\n"
          ]
        }
      ],
      "source": [
        "# setup\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "# device = torch.device('cpu')\n",
        "print(f\"Using device {device}.\")\n",
        "\n",
        "model = FS_GNN(num_users, num_items, user_fea_dim, item_fea_dim, config['hidden_dim'])\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "mse_loss = torch.nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay = WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "val_edge_index = val_edge_index.to(device)\n",
        "test_edge_index = test_edge_index.to(device)\n",
        "train_ratings = train_ratings.to(device)\n",
        "val_ratings = val_ratings.to(device)\n",
        "test_ratings = test_ratings.to(device)\n",
        "user_emb = user_emb.to(device)\n",
        "item_emb = item_emb.to(device)\n",
        "user_sem_emb = user_sem_emb.to(device)\n",
        "item_sem_emb = item_sem_emb.to(device)\n",
        "user_sim_edge_index = user_sim_edge_index.to(device)\n",
        "item_sim_edge_index = item_sim_edge_index.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYjrDp1w-hiP",
        "outputId": "3f95ff0e-c5d4-4ef3-c0b1-3c07c1552e7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Iteration 0/300] train_loss: 3.83797, val_loss: 4.01196, val_mae: 1.01228, val_rmse: 1.29565\n",
            "[Iteration 20/300] train_loss: 3.19666, val_loss: 3.36893, val_mae: 0.87059, val_rmse: 1.06487\n",
            "[Iteration 40/300] train_loss: 3.12296, val_loss: 3.31886, val_mae: 0.8523, val_rmse: 1.05323\n",
            "[Iteration 60/300] train_loss: 2.99266, val_loss: 3.31204, val_mae: 0.86989, val_rmse: 1.06598\n",
            "[Iteration 80/300] train_loss: 2.99682, val_loss: 3.3101, val_mae: 0.87422, val_rmse: 1.0705\n",
            "[Iteration 100/300] train_loss: 2.9612, val_loss: 3.3334, val_mae: 0.88666, val_rmse: 1.08287\n",
            "[Iteration 120/300] train_loss: 3.01366, val_loss: 3.28108, val_mae: 0.86104, val_rmse: 1.05949\n",
            "[Iteration 140/300] train_loss: 2.9801, val_loss: 3.30736, val_mae: 0.87725, val_rmse: 1.07343\n",
            "[Iteration 160/300] train_loss: 3.08638, val_loss: 3.33001, val_mae: 0.88796, val_rmse: 1.08355\n",
            "[Iteration 180/300] train_loss: 3.0948, val_loss: 3.33936, val_mae: 0.89343, val_rmse: 1.08892\n",
            "[Iteration 200/300] train_loss: 2.96852, val_loss: 3.30131, val_mae: 0.87489, val_rmse: 1.07118\n",
            "[Iteration 220/300] train_loss: 3.02396, val_loss: 3.29853, val_mae: 0.87338, val_rmse: 1.06967\n",
            "[Iteration 240/300] train_loss: 3.04517, val_loss: 3.30138, val_mae: 0.87581, val_rmse: 1.07157\n",
            "[Iteration 260/300] train_loss: 3.08409, val_loss: 3.29583, val_mae: 0.87256, val_rmse: 1.06908\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[50], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m pred_loss \u001b[38;5;241m+\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc_loss_lambda\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m fc_loss \u001b[38;5;241m+\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msc_loss_lambda\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m sc_loss \u001b[38;5;241m+\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecon_loss_lambda\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m recon_loss\n\u001b[0;32m     24\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 25\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     26\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m%\u001b[39m ITERS_PER_EVAL \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    489\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# training loop\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "item_fea_gae = torch.zeros((1682, 64))\n",
        "\n",
        "for iter in range(ITERATIONS):\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        range(train_edge_index.size(1)),\n",
        "        shuffle=True,\n",
        "        batch_size=BATCH_SIZE,\n",
        "    )\n",
        "    for index in train_loader:\n",
        "        # 获取批次数据\n",
        "        batch_train_edges = train_edge_index[:, index].to(device)\n",
        "        batch_ratings = train_ratings[index].to(device)\n",
        "\n",
        "        # forward propagation\n",
        "        pred_ratings, fc_loss, sc_loss, item_fea_gae= model.forward(batch_train_edges, user_sim_edge_index, item_sim_edge_index, user_emb, item_emb, user_sem_emb, item_sem_emb, device)\n",
        "        # loss computation\n",
        "        pred_loss = mse_loss(batch_ratings, pred_ratings)\n",
        "        train_loss = pred_loss + config['fc_loss_lambda'] * fc_loss + config['sc_loss_lambda'] * sc_loss\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if iter % ITERS_PER_EVAL == 0:\n",
        "        model.eval()\n",
        "        val_loss, mae, rmse = evaluation(model, val_ratings, val_edge_index, user_emb, item_emb, BATCH_SIZE, device)\n",
        "        print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_mae: {round(mae, 5)}, val_rmse: {round(rmse, 5)}\")\n",
        "        train_losses.append(train_loss.item())\n",
        "        val_losses.append(val_loss)\n",
        "        model.train()\n",
        "\n",
        "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
        "        scheduler.step()\n",
        "        \n",
        "# # 绘制热力图\n",
        "# item_fea_gae = item_fea_gae.detach().cpu()\n",
        "# row_indices = np.random.choice(item_fea_gae.shape[0], size=30, replace=False)\n",
        "# col_indices = np.random.choice(item_fea_gae.shape[1], size=30, replace=False) # Max columns is 18\n",
        "# subset_matrix = subset_matrix.cpu()\n",
        "# subset_matrix = item_fea_gae[np.ix_(row_indices, col_indices)]\n",
        "# plt.figure(figsize=(30, 30)) # 根据需要调整图像大小\n",
        "# sns.heatmap(subset_matrix, cmap='Blues', cbar=True, square=True)\n",
        "# plt.xlabel('项目特征')\n",
        "# plt.ylabel('项目')\n",
        "# plt.title('矩阵可视化')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "nLcdvV5iXBSv",
        "outputId": "9f5ea09b-34ef-4611-fb3d-ba0b6349d26f"
      },
      "outputs": [],
      "source": [
        "iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
        "plt.plot(iters, train_losses, label='train')\n",
        "plt.plot(iters, val_losses, label='validation')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')\n",
        "plt.title('training and validation loss curves')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6UjCTMQ_N5e",
        "outputId": "cbb47e93-575c-4e0d-d3a5-bdc45274f427"
      },
      "outputs": [],
      "source": [
        "# evaluate on test set\n",
        "model.eval()\n",
        "\n",
        "test_loss, test_mae, test_rmse = evaluation(model, test_ratings, test_edge_index, user_emb, item_emb, BATCH_SIZE, device)\n",
        "\n",
        "print(f\"[test_loss: {round(test_loss, 5)}, test_mae: {round(test_mae, 5)}, test_rmse: {round(test_rmse, 5)}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "lightgcn_pyg.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
